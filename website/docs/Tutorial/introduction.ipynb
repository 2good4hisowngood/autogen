{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "tags: [tutorial]\n",
    "description: Introduction to AutoGen\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AutoGen\n",
    "\n",
    "> The whole is greater than the sum of its parts. - Aristotle\n",
    "\n",
    "AutoGen is an open source framework for building multi-agent systems \n",
    "that enable complex workflows. \n",
    "In this tutorial, we introduce the basic concepts of AutoGen and show \n",
    "how to use each building blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why AutoGen?\n",
    "\n",
    "An agent is an entity that reacts to its environment. It can model real-world\n",
    "entities like people and abstract entities like algorithms. Multi-agent systems\n",
    "leverage the this abstraction to implement complex workflows as collaboration\n",
    "among agents. \n",
    "\n",
    "AutoGen provides a framework for building multi-agent systems. It is designed\n",
    "to be composable and extensible: \n",
    "you can create a complex workflow by combining simple agents,\n",
    "and you can configure each agent with customizable components.\n",
    "\n",
    "Most importantly, AutoGen is developed by a vibrant community of researchers\n",
    "and engineers. It incorporates the latest research in multi-agent systems\n",
    "and it has been used in many real-world applications, including math problem solvers,\n",
    "supply chain optimization, data analysis, market research, and game AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "An agent in AutoGen is an entity that can send and receive messages to and from\n",
    "other agents. An agent can be powered by a model, such as a large language model (LLM)\n",
    "like GPT-4, a code executor like an IPython kernel, a human, or a combination of these\n",
    "and other pluggable and customizable components.\n",
    "\n",
    "![ConversableAgent](./assets/conversable-agent.png)\n",
    "\n",
    "In AutoGen, a `ConversableAgent` is an agent with built-in components:\n",
    "\n",
    "1. A list of LLMs;\n",
    "2. A code executor;\n",
    "3. A function and tool executor;\n",
    "4. A human-in-the-loop component.\n",
    "\n",
    "These components can be switched on/off and customized to suit the need of \n",
    "specific application.\n",
    "Additional components can be added to the agent to extend its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs enable agent to converse in human languages and transform between structured and unstructured text. \n",
    "Here is an example of a `ConversableAgent` with a GPT-4 LLM switched on and other\n",
    "components switched off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ask it to generate a response to a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure thing, here's one for you:\n",
      "\n",
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role and Conversation\n",
    "\n",
    "Agents can be assigned roles and participate in conversations.\n",
    "In AutoGen, conversations are how agents make progress on a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of assigning two roles to two agents by setting their\n",
    "`system_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two comedian agents, we can ask them to start a comedy show.\n",
    "This can be done using the `initiate_chat` method.\n",
    "We set the `max_turns` to 2 to keep the conversation short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here's a classic for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a good one, Joe! Okay, here's another one:\n",
      "\n",
      "Why don't we ever tell secrets on a farm?\n",
      "\n",
      "Because the potatoes have eyes, the corn has ears, and the beansstalk!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a funny one, Cathy! Here's mine:\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comedians are boucing off each other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we introduced the concept of agent, role and conversation in AutoGen.\n",
    "For simplicity, we only used the LLM. In the [next chapter](./human-in-the-loop), \n",
    "we will show you how to use the human-in-the-loop component to provide feedback \n",
    "to the agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
