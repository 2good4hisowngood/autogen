{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "tags: [tutorial]\n",
    "description: Introduction to AutoGen\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AutoGen\n",
    "\n",
    "> The whole is greater than the sum of its parts. - Aristotle\n",
    "\n",
    "AutoGen is an open source framework for building multi-agent systems \n",
    "that enable complex workflows. \n",
    "In this tutorial, we introduce the basic concepts of AutoGen and show \n",
    "how to use each building blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why AutoGen?\n",
    "\n",
    "An agent is an entity that reacts to its environment. It can model real-world\n",
    "entities like people and abstract entities like algorithms. Multi-agent systems\n",
    "leverage the this abstraction to implement complex workflows as collaboration\n",
    "among agents. \n",
    "\n",
    "AutoGen provides a framework for building multi-agent systems. It is designed\n",
    "to be composable and extensible: \n",
    "you can create a complex workflow by combining simple agents,\n",
    "and you can configure each agent with customizable components.\n",
    "\n",
    "Most importantly, AutoGen is developed by a vibrant community of researchers\n",
    "and engineers. It incorporates the latest research in multi-agent systems\n",
    "and it has been used in many real-world applications, including math problem solvers,\n",
    "supply chain optimization, data analysis, market research, and game AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "An agent in AutoGen is an entity that can send and receive messages to and from\n",
    "other agents. An agent can be powered by a model, such as a large language model (LLM)\n",
    "like GPT-4, a code executor like an IPython kernel, a human, or a combination of these\n",
    "and other pluggable and customizable components.\n",
    "\n",
    "![ConversableAgent](./assets/conversable-agent.png)\n",
    "\n",
    "In AutoGen, a `ConversableAgent` is an agent with built-in components:\n",
    "\n",
    "1. A list of LLMs;\n",
    "2. A code executor;\n",
    "3. A function and tool executor;\n",
    "4. A human-in-the-loop interface.\n",
    "\n",
    "These components can be switched on/off and customized to suit the need of \n",
    "specific application.\n",
    "Additional components can be added to the agent to extend its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs enable agent to converse in human languages and transform between structured and unstructured text. \n",
    "Here is an example of a `ConversableAgent` with a GPT-4 LLM switched on and other\n",
    "components switched off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ask it to generate a response to a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure thing, here's one for you:\n",
      "\n",
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role and Conversation\n",
    "\n",
    "Agents can be assigned roles and participate in conversations.\n",
    "In AutoGen, conversations are how agents make progress on a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of assigning two roles to two agents by setting their\n",
    "`system_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two comedian agents, we can ask them to start a comedy show.\n",
    "This can be done using the `initiate_chat` method.\n",
    "We set the `max_turns` to 2 to keep the conversation short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here's a classic for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a good one, Joe! Okay, here's another one:\n",
      "\n",
      "Why don't we ever tell secrets on a farm?\n",
      "\n",
      "Because the potatoes have eyes, the corn has ears, and the beansstalk!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a funny one, Cathy! Here's mine:\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comedians are boucing off each other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-in-the-loop\n",
    "\n",
    "As mentioned earlier, `ConversableAgent` comes with a human-in-the-loop component.\n",
    "This is used for providing human feedback to an agent and a mechanism to \n",
    "terminate the conversation.\n",
    "The figure below shows the human-in-the-loop component and how it is used.\n",
    "\n",
    "![human-in-the-loop-component](./assets/Human-in-the-loop.png)\n",
    "\n",
    "As shown in the figure, when messages are received, they are first intercepted by\n",
    "the human-in-the-loop component, which decides whether:\n",
    "\n",
    "1. to pass the message to the other components that generates an automatic response; \n",
    "2. to \"short-circuit\" other components and returns a human response; or\n",
    "3. to terminate the conversation.\n",
    "\n",
    "There are three modes for the human-in-the-loop component, specified through\n",
    "the `human_input_mode` argument of the `ConversableAgent`:\n",
    "\n",
    "1. `NEVER`: human-in-the-loop is always skipped;\n",
    "2. `ALWAYS`: human-in-the-loop is always used, though human can choose to skip;\n",
    "3. `TERMINATE`: human-in-the-loop is only used when a termination condition is\n",
    "    met -- this is the default mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we introduced the concept of agent, role and conversation in AutoGen.\n",
    "For simplicity, we only used the LLM and human input components.\n",
    "In the next chapter, we will show you how to use code executor -- the most powerful\n",
    "component only second to LLM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
