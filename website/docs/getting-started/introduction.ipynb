{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "tags: [tutorial]\n",
    "description: Introduction to AutoGen\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AutoGen\n",
    "\n",
    "> _The whole is greater than the sum of its parts._<br>\n",
    "> -**Aristotle**\n",
    "\n",
    "Welcome! AutoGen is an open-source framework that leverages multiple _agents_ to enable complex workflows. This tutorial introduces basic concepts and building blocks of AutoGen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why AutoGen?\n",
    "\n",
    "While there are many definitions of agents, in AutoGen, an agent is an entity that reacts to its environment. This abstraction not just allows agents that model real-world and abstract entities, such as people and algorithms, but it also simplifies implementation of complex workflows as collaboration among agents.\n",
    "\n",
    "Further, AutoGen is extensible and composable: you can extend simple agent with customizable components and create workflows that can combine these agents, resulting in implementations that are modular and easy to maintain.\n",
    "\n",
    "Most importantly, AutoGen is developed by a vibrant community of researchers\n",
    "and engineers. It incorporates the latest research in multi-agent systems\n",
    "and has been used in many real-world applications, including math problem solvers,\n",
    "supply chain optimization, data analysis, market research, and game AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install from pip: `pip install pyautogen`. Find more options in [Installation](/docs/installation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "In AutoGen, an agent is an entity that can send and receive messages to and from\n",
    "other agents. An agent can be powered by a model, such as a large language model (LLM)\n",
    "like GPT-4, a code executor like an IPython kernel, a human, or a combination of these\n",
    "and other pluggable and customizable components.\n",
    "\n",
    "```{=mdx}\n",
    "![ConversableAgent](./assets/conversable-agent.png)\n",
    "```\n",
    "\n",
    "In AutoGen, a `ConversableAgent` is an agent with built-in components:\n",
    "\n",
    "1. A list of LLMs;\n",
    "2. A code executor;\n",
    "3. A function and tool executor;\n",
    "4. A human-in-the-loop component.\n",
    "\n",
    "These components can be switched on/off and customized to suit the need of \n",
    "specific application.\n",
    "Additional components can be added to the agent to extend its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs enable agent to converse in human languages and transform between structured and unstructured text. \n",
    "Here is an example of a `ConversableAgent` with a GPT-4 LLM switched on and other\n",
    "components switched off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ask it to generate a response to a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure thing, here's one for you:\n",
      "\n",
      "Why don't scientists trust atoms? \n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role and Conversation\n",
    "\n",
    "Agents can be assigned roles and participate in conversations.\n",
    "In AutoGen, conversations are how agents make progress on a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of assigning two roles to two agents by setting their\n",
    "`system_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two comedian agents, we can ask them to start a comedy show.\n",
    "This can be done using the `initiate_chat` method.\n",
    "We set the `max_turns` to 2 to keep the conversation short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, here's a classic for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a good one, Joe! Okay, here's another one:\n",
      "\n",
      "Why don't we ever tell secrets on a farm?\n",
      "\n",
      "Because the potatoes have eyes, the corn has ears, and the beansstalk!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a funny one, Cathy! Here's mine:\n",
      "\n",
      "Why was the math book sad?\n",
      "\n",
      "Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comedians are bouncing off each other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we introduced the concept of agent, role and conversation in AutoGen.\n",
    "For simplicity, we only used the LLM. In the [next chapter](./human-in-the-loop), \n",
    "we will show you how to use the human-in-the-loop component to provide feedback \n",
    "to the agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
