{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae1f50ec",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_function_call_currency_calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a71fa36",
   "metadata": {},
   "source": [
    "# Websockets: streaming with websockets\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install `pyautogen`:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b803c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"pyautogen>=0.2.3\", fastapi, uvicorn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ebd2397",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca301a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "from websockets.sync.client import connect as ws_connect\n",
    "from autogen.io.websockets import IOWebsockets\n",
    "\n",
    "import autogen\n",
    "from autogen.cache import Cache\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92fde41f",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the models with matching names are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2024-02-15-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo-16k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2024-02-15-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/website/docs/llm_configuration.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b9526e7",
   "metadata": {},
   "source": [
    "## Defining on_connect function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb85afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_connect(iostream: IOWebsockets) -> None:\n",
    "    try:\n",
    "        print(f\" - on_connect(): Connected to client using IOWebsockets {iostream}\", flush=True)\n",
    "\n",
    "        print(\" - on_connect(): Receiving message from client.\", flush=True)\n",
    "\n",
    "        initial_msg = iostream.input()\n",
    "\n",
    "        llm_config = {\n",
    "            \"config_list\": config_list,\n",
    "            \"stream\": True,\n",
    "        }\n",
    "\n",
    "        agent = autogen.ConversableAgent(\n",
    "            name=\"chatbot\",\n",
    "            system_message=\"Complete a task given to you and reply TERMINATE when the task is done.\",\n",
    "            llm_config=llm_config,\n",
    "            iostream=iostream,\n",
    "        )\n",
    "\n",
    "        # create a UserProxyAgent instance named \"user_proxy\"\n",
    "        user_proxy = autogen.UserProxyAgent(\n",
    "            name=\"user_proxy\",\n",
    "            system_message=\"A proxy for the user.\",\n",
    "            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "            human_input_mode=\"NEVER\",\n",
    "            max_consecutive_auto_reply=10,\n",
    "            code_execution_config=False,\n",
    "            iostream=iostream,\n",
    "        )\n",
    "\n",
    "        # we will use a temporary directory as the cache path root to ensure fresh completion each time\n",
    "        with TemporaryDirectory() as cache_path_root:\n",
    "            with Cache.disk(cache_path_root=cache_path_root) as cache:\n",
    "                print(\n",
    "                    f\" - on_connect(): Initiating chat with agent {agent} using message '{initial_msg}'\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                user_proxy.initiate_chat(  # noqa: F704\n",
    "                    agent,\n",
    "                    message=initial_msg,\n",
    "                    cache=cache,\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(f\" - on_connect(): Exception occurred: {e}\", flush=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef868a",
   "metadata": {},
   "source": [
    "## Testing websockets server with Python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbe004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - test_setup() with websocket server running on ws://127.0.0.1:8765.\n",
      " - _handler(): Client connected on <websockets.sync.server.ServerConnection object at 0x7f851200cf70>\n",
      " - Connected to server on ws://127.0.0.1:8765\n",
      " - on_connect(): Connected to client using IOWebsockets <autogen.io.websockets.IOWebsockets object at 0x7f851200ddb0>\n",
      " - Sending message to server.\n",
      " - on_connect(): Receiving message from client.\n",
      " - on_connect(): Initiating chat with agent <autogen.agentchat.conversable_agent.ConversableAgent object at 0x7f851200f2b0> using message 'Please write a poem about spring in a city of your choice.'\n",
      "\u001b[33muser_proxy\u001b[0m (to chatbot):\n",
      "Please write a poem about spring in a city of your choice.\n",
      "--------------------------------------------------------------------------------\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\u001b[32mAmong the bustling streets of Rome,Where ancient stones and history roam,Emerges spring with gentle nudge,Bidding farewell to winter's sludge.\n",
      "Verdant leaves on sycamores sprout,Cafés spill out with lively shout,Piazzas bask in warmer sun,As gelato days have just begun.\n",
      "The Spanish Steps in blooms are dressed,With purple wisteria, city's guest,Pilgrims and poets, share the view,Under skies of a clearer blue.\n",
      "The Tiber’s murmur tells a tale,Of springtime winds that fill the sail,Of boats that glide with easy grace,Past lovers locked in sweet embrace.\n",
      "Fountains gush a joyful song,As days stretch out and nights grow long,Laughter dances through the air,With fiori sellers hawking ware.\n",
      "Vatican gardens, a serene escape,Gilded by the sunlight's drape,Roses whisper to the saints,In hues that olden masters paint.\n",
      "The Colosseum's mighty ring,Feels the warmth that Aprils bring,Stories etched in every stone,Welcoming the vernal tone.\n",
      "Trastevere’s narrow winding ways,Blossom into longer days,Olive trees and terraces flare,With the soul of primavera there.\n",
      "So spring adorns the Eternal City,With a touch that’s soft and oh so pretty,A renaissance of life and sound,Where ancient and new are seamlessly bound.\n",
      "TERMINATE\u001b[0m\n",
      "\u001b[33mchatbot\u001b[0m (to user_proxy):\n",
      "Among the bustling streets of Rome,\n",
      "Where ancient stones and history roam,\n",
      "Emerges spring with gentle nudge,\n",
      "Bidding farewell to winter's sludge.\n",
      "\n",
      "Verdant leaves on sycamores sprout,\n",
      "Cafés spill out with lively shout,\n",
      "Piazzas bask in warmer sun,\n",
      "As gelato days have just begun.\n",
      "\n",
      "The Spanish Steps in blooms are dressed,\n",
      "With purple wisteria, city's guest,\n",
      "Pilgrims and poets, share the view,\n",
      "Under skies of a clearer blue.\n",
      "\n",
      "The Tiber’s murmur tells a tale,\n",
      "Of springtime winds that fill the sail,\n",
      "Of boats that glide with easy grace,\n",
      "Past lovers locked in sweet embrace.\n",
      "\n",
      "Fountains gush a joyful song,\n",
      "As days stretch out and nights grow long,\n",
      "Laughter dances through the air,\n",
      "With fiori sellers hawking ware.\n",
      "\n",
      "Vatican gardens, a serene escape,\n",
      "Gilded by the sunlight's drape,\n",
      "Roses whisper to the saints,\n",
      "In hues that olden masters paint.\n",
      "\n",
      "The Colosseum's mighty ring,\n",
      "Feels the warmth that Aprils bring,\n",
      "Stories etched in every stone,\n",
      "Welcoming the vernal tone.\n",
      "\n",
      "Trastevere’s narrow winding ways,\n",
      "Blossom into longer days,\n",
      "Olive trees and terraces flare,\n",
      "With the soul of primavera there.\n",
      "\n",
      "So spring adorns the Eternal City,\n",
      "With a touch that’s soft and oh so pretty,\n",
      "A renaissance of life and sound,\n",
      "Where ancient and new are seamlessly bound.\n",
      "\n",
      "TERMINATE\n",
      " - Received TERMINATE message. Exiting.\n"
     ]
    }
   ],
   "source": [
    "with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8765) as uri:\n",
    "    print(f\" - test_setup() with websocket server running on {uri}.\", flush=True)\n",
    "\n",
    "    with ws_connect(uri) as websocket:\n",
    "        print(f\" - Connected to server on {uri}\", flush=True)\n",
    "\n",
    "        print(\" - Sending message to server.\", flush=True)\n",
    "        # websocket.send(\"2+2=?\")\n",
    "        websocket.send(\"Please write a poem about spring in a city of your choice.\")\n",
    "\n",
    "        while True:\n",
    "            message = websocket.recv()\n",
    "            message = message.decode(\"utf-8\") if isinstance(message, bytes) else message\n",
    "            # drop the newline character\n",
    "            if message.endswith(\"\\n\"):\n",
    "                message = message[:-1]\n",
    "\n",
    "            print(message, end=\"\", flush=True)\n",
    "\n",
    "            if \"TERMINATE\" in message:\n",
    "                print()\n",
    "                print(\" - Received TERMINATE message. Exiting.\", flush=True)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a656564",
   "metadata": {},
   "source": [
    "## Testing websockets server running inside FastAPI server with HTML/JS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e55dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager  # noqa: E402\n",
    "from pathlib import Path  # noqa: E402\n",
    "from fastapi import FastAPI  # noqa: E402\n",
    "from fastapi.responses import HTMLResponse  # noqa: E402\n",
    "\n",
    "\n",
    "PORT = 8000\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Autogen websocket test</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>WebSocket Chat</h1>\n",
    "        <form action=\"\" onsubmit=\"sendMessage(event)\">\n",
    "            <input type=\"text\" id=\"messageText\" autocomplete=\"off\"/>\n",
    "            <button>Send</button>\n",
    "        </form>\n",
    "        <ul id='messages'>\n",
    "        </ul>\n",
    "        <script>\n",
    "            var ws = new WebSocket(\"ws://localhost:8080/ws\");\n",
    "            ws.onmessage = function(event) {\n",
    "                var messages = document.getElementById('messages')\n",
    "                var message = document.createElement('li')\n",
    "                var content = document.createTextNode(event.data)\n",
    "                message.appendChild(content)\n",
    "                messages.appendChild(message)\n",
    "            };\n",
    "            function sendMessage(event) {\n",
    "                var input = document.getElementById(\"messageText\")\n",
    "                ws.send(input.value)\n",
    "                input.value = ''\n",
    "                event.preventDefault()\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def run_websocket_server(app):\n",
    "    with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n",
    "        print(f\"Websocket server started at {uri}.\", flush=True)\n",
    "\n",
    "        yield\n",
    "\n",
    "\n",
    "app = FastAPI(lifespan=run_websocket_server)\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def get():\n",
    "    return HTMLResponse(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92e50b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2304605]\n",
      "INFO:     Waiting for application startup.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websocket server started at ws://127.0.0.1:8080.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:36252 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:36252 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      " - _handler(): Client connected on <websockets.sync.server.ServerConnection object at 0x7f8510345330>\n",
      " - on_connect(): Connected to client using IOWebsockets <autogen.io.websockets.IOWebsockets object at 0x7f85103454b0>\n",
      " - on_connect(): Receiving message from client.\n",
      " - on_connect(): Initiating chat with agent <autogen.agentchat.conversable_agent.ConversableAgent object at 0x7f851200d180> using message 'what is fibonacci sequence? give me a few examples of elements'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [2304605]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn  # noqa: E402\n",
    "\n",
    "config = uvicorn.Config(app)\n",
    "server = uvicorn.Server(config)\n",
    "await server.serve()  # noqa: F704"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb50946",
   "metadata": {},
   "source": [
    "## Testing  websockets server with HTML/JS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a98de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from http.server import HTTPServer, SimpleHTTPRequestHandler  # noqa: E402\n",
    "\n",
    "PORT = 8000\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Autogen websocket test</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>WebSocket Chat</h1>\n",
    "        <form action=\"\" onsubmit=\"sendMessage(event)\">\n",
    "            <input type=\"text\" id=\"messageText\" autocomplete=\"off\"/>\n",
    "            <button>Send</button>\n",
    "        </form>\n",
    "        <ul id='messages'>\n",
    "        </ul>\n",
    "        <script>\n",
    "            var ws = new WebSocket(\"ws://localhost:8080/ws\");\n",
    "            ws.onmessage = function(event) {\n",
    "                var messages = document.getElementById('messages')\n",
    "                var message = document.createElement('li')\n",
    "                var content = document.createTextNode(event.data)\n",
    "                message.appendChild(content)\n",
    "                messages.appendChild(message)\n",
    "            };\n",
    "            function sendMessage(event) {\n",
    "                var input = document.getElementById(\"messageText\")\n",
    "                ws.send(input.value)\n",
    "                input.value = ''\n",
    "                event.preventDefault()\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    # create a simple HTTP webpage\n",
    "    path = Path(temp_dir) / \"chat.html\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    #\n",
    "    class MyRequestHandler(SimpleHTTPRequestHandler):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, directory=temp_dir, **kwargs)\n",
    "\n",
    "        def do_GET(self):\n",
    "            if self.path == \"/\":\n",
    "                self.path = \"/chat.html\"\n",
    "            return SimpleHTTPRequestHandler.do_GET(self)\n",
    "\n",
    "    handler = MyRequestHandler\n",
    "\n",
    "    with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n",
    "        print(f\"Websocket server started at {uri}.\", flush=True)\n",
    "\n",
    "        with HTTPServer((\"\", PORT), handler) as httpd:\n",
    "            print(\"HTTP server started at http://localhost:\" + str(PORT))\n",
    "            httpd.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19656d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
